{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSE (Mean Squared Error)\n",
    "* penalize outlier errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 4 1]\n",
      "1.6666666666666667\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "y = np.array([4,3,5])\n",
    "yhat = np.array([4,5,6])\n",
    "sub = y-yhat\n",
    "sqr = sub**2\n",
    "summation = np.sum(sqr)\n",
    "mse = summation/n\n",
    "print(sqr)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE (Root Mean Squared Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.005952064639224"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 3\n",
    "y = np.array([4,3,5])\n",
    "yhat = np.array([4,100,6])\n",
    "sub = y-yhat\n",
    "sqr = sub**2\n",
    "div = sqr/n\n",
    "summation = np.sum(div)\n",
    "rmse = np.sqrt(summation)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAE (Mean Absolute Percentage Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.666666666666664"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 3\n",
    "y = np.array([4,3,5])\n",
    "yhat = np.array([4,100,6])\n",
    "sub = y-yhat\n",
    "absolute = np.abs(sub)\n",
    "summation = np.sum(absolute)\n",
    "mae = summation/n\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAPE (Mean Absolute Percentage Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 3\n",
    "y = np.array([4,6,8])\n",
    "yhat = np.array([2,3,4])\n",
    "sub = y-yhat\n",
    "perc = sub/y\n",
    "absol = np.abs(perc)\n",
    "summation = np.sum(absol)\n",
    "mape = summation/n\n",
    "mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Y and Yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([4,6,8])\n",
    "yhat = np.array([2,3,4])\n",
    "np.corrcoef(y,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999998\n",
      "1.3415758552508151e-08\n"
     ]
    }
   ],
   "source": [
    "corr, pvalue = pearsonr(y,yhat)\n",
    "print(corr)\n",
    "print(pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reasonable to use the median vs mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 15.857142857142858\n",
      "Median: 3.0\n"
     ]
    }
   ],
   "source": [
    "y = np.array([4,6,8,5,2,3,4])\n",
    "yhat = np.array([2,3,4,1,2,5,100])\n",
    "absolute_errors = abs(y - yhat)\n",
    "print(\"Mean: {}\".format(np.mean(absolute_errors)))\n",
    "print(\"Median: {}\".format(np.median(absolute_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1106/1*vMEqRXTl8PRfRtgWgwUVEg.jpeg\"\n",
    "     width=\"500\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y  - Yhat\n",
      "1  -  1  -  True\n",
      "1  -  0  -  False\n",
      "0  -  0  -  True\n",
      "0  -  1  -  False\n",
      "0  -  0  -  True\n",
      "0  -  0  -  True\n"
     ]
    }
   ],
   "source": [
    "y = np.array([1,1,0,0,0,0])\n",
    "yhat = np.array([1, 0, 0, 1, 0, 0])\n",
    "\n",
    "print(\"Y  - Yhat\")\n",
    "for i in zip(y, yhat):\n",
    "    print(i[0], \" - \", i[1], \" - \", i[0] == i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* true positive: is positive and we predicted positive\n",
    "    * y = 1 and yhat = 1\n",
    "* true negatives: is negative and we predicted negative\n",
    "    * y = 0 and yhat = 0\n",
    "* false positives: is negative but we marked as positive\n",
    "    * y = 0 and yhat = 1\n",
    "* false negatives: is positive but we marked as negative\n",
    "    * y = 1 and yhat = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positives = 1\n",
    "true_negatives = 3\n",
    "false_positives = 1\n",
    "false_negatives = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### recall\n",
    "* how many of our positive cases did we recall, or find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = true_positives/(true_positives + false_negatives)\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### precision\n",
    "* of all our true predictions, how precise were we, how many were actually true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = true_positives/(true_positives+false_positives)\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f1\n",
    "* weighed average of precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([1,1,0,0,0,0])\n",
    "yhat = np.array([1, 0, 0, 1, 0, 0])\n",
    "\n",
    "correct = 4\n",
    "n = 8\n",
    "accuracy = correct/n\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### logic extends to multilabel classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "* we split our data in training and test\n",
    "* then we divide up our data into k-folds (some arbitrary number)\n",
    "* say we have 5 folds, we will make a model on 4 folds, then use the last as a test\n",
    "* then we will pick 4 more folds, then have a new 5th fold be the test\n",
    "* we repeat this process and validate\n",
    "* test for model stability\n",
    "* cross_validate\n",
    "* The cross_validate function differs from cross_val_score in two ways:\n",
    "    * It allows specifying multiple metrics for evaluation.\n",
    "    * It returns a dict containing fit-times, score-times (and optionally training scores as well as fitted estimators) in addition to the test score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\"\n",
    "     width=\"600\" height=\"400\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "data = iris[\"data\"]\n",
    "labels = iris[\"target_names\"]\n",
    "feature_columns = iris[\"feature_names\"]\n",
    "\n",
    "df = pd.DataFrame(data, columns = feature_columns)\n",
    "df[\"label\"] = np.array([labels[x] for x in iris[\"target\"]])\n",
    "\n",
    "x = df.drop(\"label\", 1)\n",
    "y = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html\n",
    "* Evaluate metric(s) by cross-validation and also record fit/score times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(clf, x_train, y_train, cv=10, scoring = [\"precision_micro\", \"precision_macro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92307692, 1.        , 0.91666667, 1.        , 0.66666667,\n",
       "       0.83333333, 1.        , 0.91666667, 0.91666667, 0.90909091])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results[\"test_precision_micro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94444444, 1.        , 0.93333333, 1.        , 0.66666667,\n",
       "       0.88888889, 1.        , 0.93333333, 0.93333333, 0.93333333])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results[\"test_precision_macro\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are these good scores?  Look at not only the average/median but the deviation.  Are they consistent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"micro\": cv_results[\"test_precision_micro\"],\n",
    "    \"macro\": cv_results[\"test_precision_macro\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro</th>\n",
       "      <th>macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      micro     macro\n",
       "0  0.923077  0.944444\n",
       "1  1.000000  1.000000\n",
       "2  0.916667  0.933333\n",
       "3  1.000000  1.000000\n",
       "4  0.666667  0.666667\n",
       "5  0.833333  0.888889\n",
       "6  1.000000  1.000000\n",
       "7  0.916667  0.933333\n",
       "8  1.000000  1.000000\n",
       "9  0.909091  0.933333"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00199819, 0.00162983, 0.00148797, 0.00119495, 0.00118327,\n",
       "       0.00218487, 0.00161505, 0.00117612, 0.00119019, 0.00117898])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results[\"fit_time\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is an MSE of .07 good?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96      , 0.95833333, 0.83333333, 0.95833333, 0.95652174])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# won't work pushes you to cross_validate\n",
    "#cross_val_score(clf, x_train, y_train, cv=5, scoring = [\"precision_micro\", \"precision_macro\"])\n",
    "cross_val_score(clf, x_train, y_train, cv=5, scoring = \"precision_micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00190592, 0.00145197, 0.00179386, 0.001333  , 0.00133395]),\n",
       " 'score_time': array([0.00274205, 0.00211406, 0.00248909, 0.00208187, 0.00174284]),\n",
       " 'test_accuracy': array([0.96      , 1.        , 0.83333333, 0.95833333, 0.95652174]),\n",
       " 'test_recall_weighted': array([0.96      , 1.        , 0.83333333, 0.95833333, 0.95652174])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = cross_validate(clf, x_train, y_train, cv=5, scoring=('accuracy', 'recall_weighted'))\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00228906, 0.00201583, 0.00184202, 0.00183177, 0.00175023]),\n",
       " 'score_time': array([0.003052  , 0.00277829, 0.00258088, 0.00247407, 0.00235891]),\n",
       " 'test_accuracy': array([0.96      , 0.95833333, 0.83333333, 0.95833333, 0.95652174]),\n",
       " 'test_f1_weighted': array([0.9597193 , 0.95816993, 0.83068783, 0.95816993, 0.95612827])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = cross_validate(clf, x_train, y_train, cv=5, scoring=('accuracy', 'f1_weighted'))\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = DecisionTreeClassifier()\n",
    "final_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = final_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "* The simple rule is that data used for evaluating the performance of a model should not have been used to optimize the model in any way\n",
    "* training and test split\n",
    "* we can use a grid search with cross validation on the training\n",
    "* understand the stability and get the best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_map = {\n",
    "    'criterion':('gini', 'entropy'), \n",
    "    \"max_depth\":[5,7,9,11,13,15,None],\n",
    "    \"min_samples_split\":list(range(5,100,2)),\n",
    "    \"max_leaf_nodes\":list(range(10,100,5))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12096 candidates, totalling 60480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  68 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=4)]: Done 15884 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=4)]: Done 47884 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=4)]: Done 60480 out of 60480 | elapsed:   37.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n...=4,\n",
       "             param_grid={'criterion': ('gini', 'entropy'),\n",
       "                         'max_depth': [5, 7, 9, 11, 13, 15, None],\n",
       "                         'max_leaf_nodes': [10, 15, 20, 25, 30, 35, 40, 45, 50,\n",
       "                                            55, 60, 65, 70, 75, 80, 85, 90,\n",
       "                                            95],\n",
       "                         'min_samples_split': [5, 7, 9, 11, 13, 15, 17, 19, 21,\n",
       "                                               23, 25, 27, 29, 31, 33, 35, 37,\n",
       "                                               39, 41, 43, 45, 47, 49, 51, 53,\n",
       "                                               55, 57, 59, 61, 63, ...]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(clf, param_map, cv=5, verbose = 1, n_jobs = 4)\n",
    "gs.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=4,\n",
       "             param_grid={'criterion': ('gini', 'entropy'),\n",
       "                         'max_depth': [5, 7, 9, 11, 13, 15, None],\n",
       "                         'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 5,\n",
       " 'max_leaf_nodes': 10,\n",
       " 'min_samples_split': 5}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give our best params\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_criterion', 'param_max_depth', 'param_min_samples_split', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elements of our grid search object that was returned\n",
    "gs.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 0.96666667, 0.95333333, 0.96666667, 0.96666667,\n",
       "       0.96666667, 0.96666667, 0.96666667, 0.96666667, 0.96666667,\n",
       "       0.96666667, 0.96666667, 0.96666667, 0.96666667, 0.96666667,\n",
       "       0.96666667, 0.96666667, 0.96666667, 0.96666667, 0.96666667,\n",
       "       0.96666667, 0.96666667, 0.96666667, 0.96666667, 0.96666667,\n",
       "       0.96666667, 0.96666667, 0.96      , 0.96666667, 0.95333333,\n",
       "       0.96666667, 0.96666667, 0.96666667, 0.96666667, 0.96666667,\n",
       "       0.96666667, 0.96666667, 0.96666667, 0.95333333, 0.96666667,\n",
       "       0.96666667, 0.96666667, 0.96666667, 0.96666667, 0.96666667,\n",
       "       0.96666667, 0.96666667, 0.95333333, 0.96666667, 0.96666667,\n",
       "       0.96666667, 0.96666667, 0.96666667, 0.96666667, 0.96      ,\n",
       "       0.96666667, 0.96666667, 0.96666667, 0.96666667, 0.96666667,\n",
       "       0.96666667, 0.96666667, 0.96666667, 0.95333333, 0.95333333,\n",
       "       0.95333333, 0.96      , 0.96      , 0.96      , 0.96      ,\n",
       "       0.96      , 0.96      , 0.95333333, 0.95333333, 0.95333333,\n",
       "       0.96      , 0.96      , 0.96      , 0.96      , 0.96      ,\n",
       "       0.96      , 0.95333333, 0.95333333, 0.95333333, 0.96      ,\n",
       "       0.96      , 0.96      , 0.96      , 0.96      , 0.96      ,\n",
       "       0.96      , 0.95333333, 0.95333333, 0.96      , 0.96      ,\n",
       "       0.96      , 0.96      , 0.96      , 0.96      , 0.95333333,\n",
       "       0.95333333, 0.95333333, 0.96      , 0.96      , 0.96      ,\n",
       "       0.96      , 0.96      , 0.96      , 0.95333333, 0.95333333,\n",
       "       0.95333333, 0.96      , 0.96      , 0.96      , 0.96      ,\n",
       "       0.96      , 0.96      , 0.95333333, 0.95333333, 0.95333333,\n",
       "       0.96      , 0.96      , 0.96      , 0.96      , 0.96      ,\n",
       "       0.96      ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.cv_results_[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03265986, 0.03651484, 0.03651484, 0.02108185, 0.02108185,\n",
       "       0.02108185, 0.02108185, 0.02108185, 0.02108185, 0.03399346,\n",
       "       0.03399346, 0.03651484, 0.02108185, 0.02108185, 0.02108185,\n",
       "       0.02108185, 0.02108185, 0.02108185, 0.03651484, 0.03399346,\n",
       "       0.03651484, 0.02108185, 0.02108185, 0.02108185, 0.02108185,\n",
       "       0.02108185, 0.02108185, 0.03265986, 0.03399346, 0.03651484,\n",
       "       0.02108185, 0.02108185, 0.02108185, 0.02108185, 0.02108185,\n",
       "       0.02108185, 0.03265986, 0.03399346, 0.03651484, 0.02108185,\n",
       "       0.02108185, 0.02108185, 0.02108185, 0.02108185, 0.02108185,\n",
       "       0.03265986, 0.03399346, 0.03651484, 0.02108185, 0.02108185,\n",
       "       0.02108185, 0.02108185, 0.02108185, 0.02108185, 0.03651484,\n",
       "       0.03265986, 0.03399346, 0.02108185, 0.02108185, 0.02108185,\n",
       "       0.02108185, 0.02108185, 0.02108185, 0.03399346, 0.03399346,\n",
       "       0.03399346, 0.02494438, 0.02494438, 0.02494438, 0.02494438,\n",
       "       0.02494438, 0.02494438, 0.03399346, 0.03399346, 0.03399346,\n",
       "       0.02494438, 0.02494438, 0.02494438, 0.02494438, 0.02494438,\n",
       "       0.02494438, 0.03399346, 0.03399346, 0.03399346, 0.02494438,\n",
       "       0.02494438, 0.02494438, 0.02494438, 0.02494438, 0.02494438,\n",
       "       0.03399346, 0.03399346, 0.03399346, 0.02494438, 0.02494438,\n",
       "       0.02494438, 0.02494438, 0.02494438, 0.02494438, 0.03399346,\n",
       "       0.03399346, 0.03399346, 0.02494438, 0.02494438, 0.02494438,\n",
       "       0.02494438, 0.02494438, 0.02494438, 0.03399346, 0.03399346,\n",
       "       0.03399346, 0.02494438, 0.02494438, 0.02494438, 0.02494438,\n",
       "       0.02494438, 0.02494438, 0.03265986, 0.03399346, 0.03399346,\n",
       "       0.02494438, 0.02494438, 0.02494438, 0.02494438, 0.02494438,\n",
       "       0.02494438])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.cv_results_[\"std_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "                       max_features=None, max_leaf_nodes=10,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=5,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoML Options\n",
    "* http://docs.h2o.ai/h2o-tutorials/latest-stable/h2o-world-2017/automl/index.html\n",
    "* https://automl.github.io/auto-sklearn/master/manual.html#inspecting-the-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
